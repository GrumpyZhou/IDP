{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADMM applied in Neural Networks with Mnist dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Preparation with environment for notebook\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from NeuralNetwork.data_utils import *\n",
    "\n",
    "# Allow inline matplotlib figures appear in the notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Allow auto-reload of external modules \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Loading of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (60000, 28, 28)\n",
      "Training labels shape:  (60000,)\n",
      "Test data shape:  (10000, 28, 28)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load Mnist Data\n",
    "mnistDir = \"NeuralNetwork/MnistData\"\n",
    "X_train,Y_train,X_test,Y_test = getMnistData(mnistDir)\n",
    "\n",
    "# Check the size of the training and test data.\n",
    "print 'Training data shape: ', X_train.shape\n",
    "print 'Training labels shape: ', Y_train.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAABaCAYAAADkQh/tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFqBJREFUeJzt3XmUVNW1x/HvpkGNymCQ0MY8CSoITiDggOGBRkU0CkQT\n1CgBYoSnoqgBJYpJUBQjhvXAAQgiRHFFXYmCUzQqigMJD2PiUnFA1OAAtlFaQQERzvuj2LeqB+iB\nW3Vvlb/PWi7p7uqufbtu3T53n332sRACIiIiInFoknQAIiIiUjo0sBAREZHYaGAhIiIisdHAQkRE\nRGKjgYWIiIjERgMLERERiY0GFiIiIhKboh1YmNlTZrbOzD4zszVm9mrSMcXJzHYzs/vMbK2ZvW1m\nZyQdU76YWYctr+XtSccSJzM738yWmNl6M7st6Xjyxcw6mdkTZlZpZm+Y2cCkY4qLme1gZrea2Ttm\n9qmZvWBm/ZKOK25fh3PVzO4ws5VbztPXzOzspGOKU5pew6IdWAABOC+E0CKE0DyE0DnpgGJ2C7Ae\naAOcBUwzs1I7RncT8H9JB5EH7wNXA7OSDiRfzKwMmA/cD+wGjADmmtm+iQYWn6bACuC/QwgtgSuB\ne8xsr2TDil3Jn6vARKB9CKEV0B+YYGaHJBxTnFLzGhbzwALAkg4gH8xsZ+AUYFwIYV0I4TkyF+/B\nyUYWPzM7HVgNPJF0LHELIcwLIdwPfJJ0LHnUCdgjhDAlZDwJPEeJnKshhC9CCFeFEN7d8vFDwNtA\n92Qji9fX4VwNISwNIazf8qGRuTndJ8GQYpWm17DYBxYTzazCzJ4xsz5JBxOjjsDGEMLynM+9CByQ\nUDx5YWYtgPHAJZToIPFryoADkw4iH8ysLdABeCXpWKThzOxmM/sceBX4AHg44ZBKUjEPLC4F9gb2\nBGYCD5hZ+2RDis2uwGfVPvcZ0DyBWPLpKmBmCOGDpAORRnsdqDCz0WbW1Mz6An2AnROOK3Zm1hSY\nC8wJIbyRdDzScCGE88lcX3sB9wIbko2oNBXtwCKEsCSE8HkIYWMI4XYy6dcTk44rJmuBFtU+1xJY\nk0AseWFmXYFjgf9NOhZpvBDCV8BA4CRgJXAxcDfwXpJxxc3MjMygYgNwQcLhyHbYMmW3CPgv4Nyk\n4ylFTZMOIEaB0kmnvwE0NbN9cqZDulBa6dc+QDtgxZaL9q5AmZntH0LokWxo0hAhhJeBo/xjM3sO\nmJNUPHkyC9gdODGEsCnpYCQWTSmhGos0KcqMhZm1NLO+ZrajmZWZ2ZnAfwOPJB1bHEIIX5BJ011l\nZjubWS/gZOCOZCOL1Qwyb+quZAZN04EHgb5JBhWnLefmTkAZmYHijltWUZQUMztoy7HtbGajgXJK\naGBhZtPJFKn2DyF8mXQ8+VDq56qZtTGz08xsFzNrYmbHA6cDjycdW1zS9BoW5cACaAZMACqAj4Dz\ngQEhhDcTjSpe55OZp64gk4L9nxBCyfTqCCGsDyFU+H9kpn/WhxASr2iO0TjgC+Ay4Mwt/74i0Yjy\nYzCZaZBVwNHAcSGEjcmGFI8ty0qHkxkAf7ilZ85nJdhXptTP1UBm2uNdMqsmrgdGbVnlUypS8xpa\nCCGJ5xUREZESVKwZCxEREUkhDSxEREQkNhpYiIiISGw0sBAREZHY5L2PhZkVdXVoCKHO3hilfozF\nfnxQ+seo8zSj1I+x2I8PSv8YdZ4qYyEiIiIx0sBCREREYqOBhYiIiMRGAwsRERGJjQYWIiIiEhsN\nLIpI9+7dmT17NrNnz2bTpk1s2rQp+rhbt25JhyciRWjKlClMmTKFEAIvvfQSL730Eu3ataNdu3ZJ\nhyZFSgMLERERiU3eNyHLx3rdsrIyWrZsWePzI0eOBGDnnXcGYL/99gPg/PPP54YbbgDgjDMymxKu\nX7+e6667DoDx48dv9bnSsCa5a9euACxYsIAWLVrU+phPP/2U1q1bN+rnF9O68mOOOQaAO++8kz59\n+gDw+uuv1/l9aT7GcePGAZnzsEmTzFj/qKOOAmDhwoX1+hlpOE/zLU3H2Lx5c3bddVcAfvCDHwDQ\npk0bACZPnsyGDRsa9XMLeZ5+97vfBeAf//gHAK1atcL/HvgxPfroo3E9XaSQx9ixY0cAmjVrRu/e\nvQG45ZZbANi8efM2v3f+/PkAnH766QB8+eWX9XrOpM7TZs2aceSRRwJw7bXXAvC9730v7qcB6j7G\nvDfIaqy99tqLHXbYASD6ZfXq1QvIvAFOPfXUOn/Ge++9B8DUqVP54Q9/CMCaNWsAePHFF+t90U7K\nYYcdBsCf//xnAFq2bBm98f04/GRv3bo1RxxxBAAvvPBCla/lk79ZW7duzX333Zf35zv00EMBWLJk\nSd6fK9+GDh0KwGWXXQZUvdBp1+F08T/C/lr17NmTAw88sNbH7rHHHlx44YWFCq3RPvroIwCefvpp\nAPr3759kOLE44IADgOx768c//jEATZo04dvf/jaQfZ/V9R7z38f06dMBuOiii/jss89ijzkuLVu2\n5MknnwRg1apVAJSXl0f/LiRNhYiIiEhsUpexyE371zbdUR8+IvUU89q1a7nzzjsBWLlyJQCrV6+u\nVwq90Hwap1u3bsydOxfI3AFVt2zZMgCuv/56AO666y6ee+45IHvcEydOzHu8nrLv0KFDXjMWPkXQ\nvn17ANq1a4dZnRnHVPPiuJ122inhSBrv8MMP56yzzgKIpqb8rhFg9OjRAHzwwQdAJuvo5/XixYsL\nGWqDderUCcjcqZ555pkAfOMb3wDAzHj33XeBbPawc+fOAAwaNChKt7/22msFjbkhPv/8cwD+/e9/\nJxxJfPyad+KJJ8b2M3/6058CMGvWrOgam3bl5eXR/5WxEBERkaKWuozFihUrAPj444/rlbHwu57K\nykqOPvpoIFtbcMcdd+QpyvyZMWMGkC0y3RpfXuoFZAsXLoyyBwcffHD+AqzGR/N/+9vf8vo8nrU5\n55xzAJg7d26q7wa35dhjjwXgggsuqPL51157jZNOOgmADz/8sOBxNcRpp50GZJYq7r777gBRBump\np56KChknTZpU5fvMLPqaF8WlhV9vfvvb3wLZY2zevHmNxy5btozjjz8eyBTNQTY7sfvuu0e/kzRr\n1aoVAF26dEk4kvg89thjQM2MRUVFBbNmzQKy2c/cmiav4/OsW7FLOpubuoHFJ598AsCYMWOii+w/\n//lPIFOE6f71r38BcNxxxwGZtJ6nYEeNGlWweOPSvXt3IFuNnXtieJHpAw88EK1u8dSy/25Wr17N\n97///Rrfm2/+Js23W2+9tcrHPhVUbHr16sXs2bMBagycJ02alNq0dNOmmUtFjx49AJg5cyaQmbrz\n4r+rr74agGeffZYdd9wRgHvuuQeAvn37Rj/r+eefL0zQDeQF3j//+c+3+pjly5cDmeuOT4Xsu+++\n+Q8uD3zada+99qrxNS+S9sFSWs/L6qZNmwbAvHnzqnx+48aN25wS8NV2L7/8MkBU6Jn7s9J63tbG\nC1OTmmbVVIiIiIjEJnUZCzdv3jwWLFgAZIujPGV39tlnR3fuXoAE8MorrwAwfPjwQoa6XbxY1VN4\nPnIOIfCXv/wFyE6L9OnTJyrM9Dt4XzL24osvRqk9z3p069YtWnoaN59uadu2bV5+fnXV7+7991Vs\nhgwZUuVuCDJTBwC33357AhHVjxdoVs8cPfbYY9GUQe5SPP9cbqYCMkvA//CHP+Qz1EbzpYnVvfPO\nO9HyZl9u6tkKyBZtFhvPes6ZMweA3/zmN9HX/N+VlZUA3HTTTYUMrdG++uoroOrrUx8+rbXbbrvV\n+Jq3LWhsb5Ik9ejRg7///e8Ff15lLERERCQ2qc1YADWakXz66afRv72I7+677wbq7qKWRh07dmTM\nmDFA9o78P//5D5BZFut3dmvXrgXgoYce4qGHHqrz5/qSuF/84hfRMrm4eXGUP1e+eEbEl5m6999/\nP6/PGzcv5vvZz34Wnat+NzhhwoTE4qqPq6++mssvvxzIzt36cspx48bV2jToiiuuqPVnXXjhhVGW\nLW38muIZz7/+9a8AvPnmm1RUVGz1+wqVtcsXr43JzVh8XXgBsb/2tV3PfvWrXxU0psb66quvor+R\n/vdkn332SSQWZSxEREQkNqnOWFTnI+ru3btHy4J86Z7fXRQDr5i/4YYbojt/ryPx5ZvPP//8dmcD\naqv2jovvw+K8viVuXkvjd4VvvPEGkP19pZ23gva27LluvPFGgKgNb9r4ndrll18eLeH2vSO81mDd\nunXR470CvW/fvtG55yuUPCvj+y+kkdccNPTOvWfPnnmIpvCaNGlSlJnfhvIs7tixY6MVPb5kOJev\nPNy4cWPhgtsOlZWVPPPMMwDRisqkFNXAwgs1zznnnKgo0Ze9Pfnkk9FyoJtvvhlI734LhxxyCFB1\nrfWAAQOA+m86lTZx7N3hhav9+vUDMgWD1Yv/PG3r0whp58eS21vkiSeeADI9INLI+xucd955QOZ9\n5AOKgQMH1ni8X5y9u60vnQb405/+BGQ7xBYr3/tjl112qfG1gw46qMrHixYtyntfl3zYvHlzaq+Z\n9eUD+cGDBwPZG89cvudUbcfq03pjx47l4YcfBqoOnqV+NBUiIiIisSmqjIVbvnx5tHudNxsaPHhw\nNEr1uwpfvuf7g6TF5MmTgUya2DMUcWQqausoVyjf/OY3t/q1Ll26RClxv4P4zne+A8AOO+wQpSY9\nfr9DWLx4cbTEyxs0+RbPxWDgwIFcd911VT737LPPMmTIEKBqMXKa+K7Cud0j/Y79W9/6FgDDhg0D\nMjtA+i6f3gU2hBDdDfq+ILnLwtPOG0ftv//+APz617+u0cmxtmkDn0oZNmwYmzZtKkCkkuvAAw/k\n/vvvBxo/DexTCb///e9jiytJrVu3TuR5lbEQERGR2BRlxgKIdtL01s6TJ0/mmGOOAeDaa68FsrtH\nXnPNNalYnugFNd4UK4QQjbDj4HdQfrfoxUf54FkFf67p06dHSxKrO/jgg6OMhTew+eKLLwBYunQp\nt912G5BtmevZmw8//DBqTuOFrMWwP8i2Cjbfeuut1O8D4oWaviy0TZs2vP3220Dt89J+p+7z03vs\nsUe0bPqBBx7Ie7xxaNasWVT75K+b70+zbt266Bi9dqJfv35RZsN5Vu2UU06J6mf8dymF4deZbW1r\nsK3Mrl+jTzjhhKhBYTHr379/Is9btAML573dBw0axMknnwxkp0dGjBgBZLb09j1FkuR/HD3VXFFR\nEfXhaCxfYZJbye4dS3/5y19u18/eFi/s8z0EfBOf2qxYsSLqt//qq68C1Ksb3PDhw6MNq956663t\nireQfMVEbReu6lMjaeSFsV6o+eCDD0ZTXb5Xhq/umDNnTrS/z1133QVk/iD7v9PO34v9+vXj3nvv\nrfK18ePHA5n3k2+X7b+HBQsWRFNAzs/ViRMnRpsp+nlfDF0ba5ve6d27N1AcnTdffvnlaCNG7xTr\nRcfr16+v9XvOPvtsoOaGgMXKV5glvSpEUyEiIiISm6LPWLjKyspom3Tfz8BTk717945Gsr4vQxps\n2LCh0YWlnqnwvUPGjBkTTRv87ne/A7IdO/PJt5jOB5/agtqnFdLGp7iqL5GF7B3+66+/XtCYtsfi\nxYuB7J341vhdrfeW2bx5c+ozTN63wLMS3gEXiFLg3meksrIy+h34EsSDDjoomubwpbSewRgwYEC0\n9Pbxxx8HMu+T1atXV4khn1OVjVHbctNTTjkFyBSyLl26NImwGsQzqNdcc029Hu+Z3lLJWHimzDVr\n1iwqCSjkDrXKWIiIiEhsij5j4Y2HfvSjH3HooYcC2UyFW7p0KU8//XTBY6tLYwo3/a7Y77B8F8n5\n8+dz6qmnxhdcynixbpp599fcHRK9lsSXR5cirx3KLR5Oc41FWVlZ1Ght9OjRQGY57NixY4FsrYjX\nmvTo0SOqMfACz2XLlnHuuecC2Xltb/B25JFHRkuovXgudzde33mz+v43SZs+fXpUl1bd8OHDueii\niwocUf75rqalwovjnZlF2e1CUsZCREREYlOUGYv99tuPkSNHAtk5wPLy8hqP8yY1K1euTEUP/OpL\noQYOHMioUaPq/f0XX3wxV155JZDdvc7ncn2PEUmON6PJPdd8F9BC1LskxSvvi8Xw4cOjTIUvex4x\nYkSUcTriiCOAbBOwE044IcrKXHXVVUBm5ZlnHpwvt33kkUd45JFHADjjjDMA+MlPfhI97uKLL47/\noGJQDEu5c3mdjNc0LViwoEHtt4cNG5batvqN5bVc/lp26tQpyjT5Sr5CKIqBhQ8a/E06cuTIqFdA\nbbwfghfwxNkrYnt4YZT/v7y8nKlTpwJEvRw+/vhjIHNx806iXbp0ATLdKr04xy/m/oerVPkgrGPH\njkD9lqkWmi9v9vXxuRYtWlTocAqu2NLJudtgl5WVAZmpRS/k871PcvnXJk6cCFDvzpp//OMfq/w/\nzW688caoiLH6dtujRo2Kill9yXGSevXqxRVXXAEQtRJo3759jcFeLl8q7F1UJ0+eXKMXiQ9MtrY8\ntVj4IHnPPffkkksuKfjzaypEREREYpPajEXbtm2jXv1eONWpU6etPn7x4sVMmjQJyKaD0jD9sS1l\nZWVResoLLz2d2qFDhxqPX7RoUVQolnvXVco8u1NbNiANunbtGu1/4uebL0O8+eabU99lMw577713\n0iE0yKpVq6Llo17Y5llByC4p9YLvefPm8c477wD1z1QUq1deeQWo+Zqm7Vp600031WhQdumll7Jm\nzZqtfo9nNrp16wZU7SLrbQimTZsGZAtyi10IIZHur+m8WouIiEhRSk3Gwue/ZsyYAWTuBLd1J+Rz\n194M6tFHH21Q4U4SfJ+BJUuWAETLYyFbR9K2bdvoc15v4cvfGlLoWWp69uwJZFpIp0mrVq1qFA77\nvjReIFjqfEfIJHfXbYjevXtH7cr97rWioiKqc/JGVl/HfT58V0/fHqGY+PLf+qqoqIj2svFra7HX\nVlTXokULBgwYABR2yX6iA4vDDz8cyBROHXbYYUCm2GRrvIJ76tSp0UZjxbQds3fG9JUsI0aMiDpn\nVjdlypQoLffmm28WJsAU2tZmQpIOvl+Pbwi49957R8V/vpFZmqxZsybq0uv/lwzvrul7+nTu3DnJ\ncLZq6NChUaHpkCFD6nz88uXLo78fuVuj+7lbagYNGgRkujv7a1lImgoRERGR2Fht2yDH+gRmW30C\n3+kxt0+/W7p0KQ8++CCQ7Sbm0x7eEa8QQgh13jJv6xiLQV3HmNTxDR06NEpPz5w5E2CrnQHrkq9j\nLC8vj3ao7dWrF0C0xXhtyxbzJQ3nqXcXvfXWW1m4cCGQ3YMhjn0m0nCM+ZbW92Kc4jpGL7z1827C\nhAlR11vfVdY7ns6fP59Vq1Y1LuAGSsN56tPnnTt3jrq/xrlXSF3HqIyFiIiIxCbRjEUxSMPoM990\nl1T8x5iG89T3yrjnnnuiJbj33nsvkO1iuT01UWk4xnwr9fMUSv8YdZ4qYyEiIiIxUsaiDhp9Fv/x\nQekfY5rO0xYtWkTt9H0JoO9CvD21Fmk6xnwp9fMUSv8YdZ5qYFEnnSTFf3xQ+seo8zSj1I+x2I8P\nSv8YdZ5qKkRERERilPeMhYiIiHx9KGMhIiIisdHAQkRERGKjgYWIiIjERgMLERERiY0GFiIiIhIb\nDSxEREQkNhpYiIiISGw0sBAREZHYaGAhIiIisdHAQkRERGKjgYWIiIjERgMLERERiY0GFiIiIhIb\nDSxEREQkNhpYiIiISGw0sBAREZHYaGAhIiIisdHAQkRERGKjgYWIiIjERgMLERERic3/AwEkrueu\nGcbYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x105b63e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display part of the Mnist data\n",
    "for xi in range(0,9):\n",
    "    plt.subplot(1,10,xi+1)\n",
    "    plt.imshow(X_train[xi])\n",
    "    plt.axis('off')\n",
    "    plt.title(Y_train[xi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784) (55000,)\n"
     ]
    }
   ],
   "source": [
    "#Load dataset from tensorflow\n",
    "import NeuralNetwork.TensorFlow.input_data as input_data\n",
    "fake_data = False\n",
    "train_dir = 'data'\n",
    "batch_size = 55000\n",
    "data_sets = input_data.read_data_sets(train_dir, fake_data).train\n",
    "tfX, tfY = data_sets.next_batch(batch_size,fake_data)\n",
    "print tfX.shape, tfY.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predefined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get MiniPatch\n",
    "def getMiniPatch(X_train, Y_train, X_test, Y_test, trNum, teNum, transposed):\n",
    "    # Subsample the data for more efficient code execution \n",
    "    trainNum = trNum\n",
    "    #mask = range(trainNum)\n",
    "    mask = range(5000,trainNum)\n",
    "    Xtr = X_train[mask]\n",
    "    Ytr = Y_train[mask]\n",
    "    \n",
    "    testNum = teNum\n",
    "    mask = range(testNum)\n",
    "    #mask = range(5000,5000+testNum)\n",
    "    Xte = X_test[mask]\n",
    "    Yte = Y_test[mask]\n",
    "    \n",
    "    # Reshape the image data into rows\n",
    "    Xtr = np.reshape(Xtr, (Xtr.shape[0], -1))\n",
    "    Xte = np.reshape(Xte, (Xte.shape[0], -1))\n",
    "   \n",
    "    # print Xtr.shape, Xte.shape\n",
    "    if not transposed:\n",
    "        return Xtr, Xtr, Ytr, Yte\n",
    "    else:\n",
    "        return preprocess(Xtr.T), Xte.T, Ytr, Yte\n",
    "\n",
    "def preprocess(X):\n",
    "    \n",
    "#     # return X\n",
    "#     X = X.astype(np.float64)\n",
    "#     # Mean subtraction\n",
    "#     X -= np.mean(X)  \n",
    "#     # Normalization\n",
    "   # X /= np.std(X, axis = 0)\n",
    "    return X\n",
    "\n",
    "def calLossWithTF(Y_tr, logits):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        sess = tf.InteractiveSession()\n",
    "        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "          logits, np.int64(Y_tr), name='xentropy')\n",
    "        loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    return sess.run(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparasion between ours and TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and predict with dataset from TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import NeuralNetwork.TensorFlow.simple_nn as tfnn\n",
    "from NeuralNetwork.neural_network import *\n",
    "import time\n",
    "\n",
    "# Parameters initialization\n",
    "trNum = batch_size\n",
    "hiddenLayer = [300]\n",
    "classNum = 10 \n",
    "epsilon= 0.0001 \n",
    "\n",
    "weightConsWeight = 10\n",
    "activConsWeight = 15\n",
    "iterNum = 20\n",
    "hasLambda = True\n",
    "tic = time.time()\n",
    "calLoss = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]   [[]]   [[], []]\n",
      "Initializing a neural network with :  1  hidden layers, hidden layer dimension: [300]\n",
      "(300, 784)\n",
      "Prediction accuracy: 0.875000\n",
      "Loss by us: 2.24867793747\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train our own neural network\n",
    "X_tr, Y_tr = tfX.T, tfY\n",
    "network = NeuralNetwork(X_tr, Y_tr, classNum, hiddenLayer, epsilon)\n",
    "network.train(weightConsWeight, activConsWeight, iterNum, hasLambda, calLoss, lossType = 'smx',\n",
    "              minMethod = 'prox', tau= 0.01, ite= 25)\n",
    "# Predict\n",
    "Ypred, z = network.predict(X_tr)\n",
    "print 'Prediction accuracy: %f' %np.mean(Ypred == Y_tr)\n",
    "\n",
    "# Calculate loss \n",
    "loss = calLossWithTF(Y_tr, z.T)\n",
    "print 'Loss by us:', loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3 4 6 1 8 1 0 9 8] [7 3 4 6 1 8 1 0 9 8]\n",
      "(784, 55000)\n",
      "(55000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print Y_tr[range(10)], tfY[range(10)]\n",
    "print tfX.T.shape\n",
    "print tfY.shape\n",
    "np.sum(X_tr - tfX.T) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed our network with W from TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "Step 1999: loss = 0.34\n",
      "Loss by TF: 0.340637\n",
      "Our side:\n",
      "Prediction accuracy: 0.894582\n",
      "Loss by us: 0.389213\n"
     ]
    }
   ],
   "source": [
    "# Get trained weight from tensor flow\n",
    "w1,w2,loss_ft,logit = tfnn.getTrainedWeight(hiddenLayer[0])\n",
    "print 'Loss by TF:',loss_ft\n",
    "\n",
    "# Feed into our network\n",
    "w = [np.zeros((0))]\n",
    "w.append(w1.T)\n",
    "w.append(w2.T)\n",
    "Ypred_, z_us = network.predictByFeed(X_tr, w)\n",
    "loss_us = calLossWithTF(Y_tr, z_us.T)\n",
    "print 'Our side:'\n",
    "print 'Prediction accuracy: %f' %np.mean(Ypred_ == Y_tr)\n",
    "print 'Loss by us:', loss_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10) (10, 55000)\n",
      "(100, 10)\n",
      "0.421749\n"
     ]
    }
   ],
   "source": [
    "print logit.shape,z_us.shape\n",
    "#np.sum(logit - z_us)\n",
    "\n",
    "i = range(54900,55000)\n",
    "print z_us.T[i,:].shape\n",
    "loss = calLossWithTF(Y_tr[i], z_us.T[i,:])\n",
    "print loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]   [[]]   [[], []]\n",
      "Initializing a neural network with :  1  hidden layers, hidden layer dimension: [300]\n",
      "Loss cal by us with w from TF: 2.30258509251\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss of TF's W with our loss function\n",
    "network = NeuralNetwork(X_tr[:,i], Y_tr[i], classNum, hiddenLayer, epsilon)\n",
    "loss_us_ = network.softMaxLossTest(w)\n",
    "print 'Loss cal by us with w from TF:', loss_us_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test NeuralNetwork\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hasLambda =  True\n",
      "Xtr:  (784, 600) Xte:  (784, 10) Ytr:  (600,) Yte:  (10,)\n",
      "[]   [[]]   [[], []]\n",
      "Initializing a neural network with :  1  hidden layers, hidden layer dimension: [300]\n",
      "Total training time: 7.639514s\n",
      "(300, 784)\n",
      "Prediction accuracy: 0.300000\n"
     ]
    }
   ],
   "source": [
    "from NeuralNetwork.neural_network import *\n",
    "import time\n",
    "\n",
    "\n",
    "case = [(600,10)]#,(5000,50)]#,(500,10),(5000,10),(5000,500),(20000,500),(20000, 2000)]\n",
    "lam = [True]\n",
    "i = 0\n",
    "for la in lam:\n",
    "    print 'hasLambda = ',la\n",
    "    for (trNum,teNum) in case:\n",
    "        X_tr, X_te, Y_tr, Y_te = getMiniPatch(X_train, Y_train, X_test, Y_test, trNum, teNum, 1)\n",
    "        print 'Xtr: ', X_tr.shape, 'Xte: ', X_te.shape, 'Ytr: ', Y_tr.shape, 'Yte: ', Y_te.shape\n",
    "        \n",
    "        # Initialize network\n",
    "        hiddenLayer = [300]\n",
    "        classNum = 10 \n",
    "        epsilon= 0.0001 \n",
    "        #epsilon = np.sqrt(2.0/trNum)\n",
    "        network = NeuralNetwork(X_tr, Y_tr, classNum, hiddenLayer, epsilon)\n",
    "        # Train\n",
    "        weightConsWeight = 10\n",
    "        activConsWeight = 15\n",
    "        iterNum = 20\n",
    "        hasLambda = la\n",
    "        tic = time.time()\n",
    "        calLoss = False\n",
    "        \n",
    "        \"\"\" \n",
    "        Input:\n",
    "        weightConsWeight, activConsWeight\n",
    "        iterNum:    iteration to perform Admm updates\n",
    "        hasLambda:  whether include Lambda update\n",
    "        lossType:   one of {'hinge', 'msq', 'smx'}, default is 'smx'\n",
    "        minMethod:  if lossType is 'smx', the method to minimize the zLastUpdate has to be specified (for it's not in closed form), \n",
    "                    it can be one of {'prox','gd','newton'}, default is 'prox';\n",
    "        tau, ite:   if lossType is 'smx', the step size and iteration of gradient descent/proximal gradient have to be specified, \n",
    "                    default: tau=0.01, ite=25; \n",
    "        \"\"\"\n",
    "        #network.train(weightConsWeight, activConsWeight, iterNum, hasLambda,lossType = 'hinge')\n",
    "        network.train(weightConsWeight, activConsWeight, iterNum, hasLambda, calLoss, lossType = 'smx',\n",
    "                      minMethod = 'prox', tau= 0.01, ite= 25)\n",
    "        toc = time.time()\n",
    "        print 'Total training time: %fs' % (toc - tic)\n",
    "\n",
    "        # Predict\n",
    "        Ypred = network.predict(X_te)\n",
    "        print 'Prediction accuracy: %f' %np.mean(Ypred == Y_te)\n",
    "        \n",
    "        L = len(hiddenLayer)\n",
    "        if calLoss:\n",
    "            fig = plt.figure()\n",
    "            gs = gridspec.GridSpec(5,L)\n",
    "          \n",
    "            dataLoss = fig.add_subplot(gs[0,:])\n",
    "            dataLoss.set_title('loss function')\n",
    "            dataLoss.plot(network.dataLoss, 'k-')\n",
    "\n",
    "            for l in range(0,L):\n",
    "                aloss = fig.add_subplot(gs[1,l])\n",
    "                aloss.set_title('constraint a = hz, layer = %d' % (l+1))\n",
    "                aloss.plot(network.aConstrLoss[l], 'g-')\n",
    "                \n",
    "                zloss = fig.add_subplot(gs[2,l])\n",
    "                zloss.set_title('constraint z = wa, layer = %d' % (l+1))\n",
    "                zloss.plot(network.zConstrLoss[l], 'b-')\n",
    "                \n",
    "#             lag = fig.add_subplot(gs[3,:])\n",
    "#             lag.set_title('lagrange term')\n",
    "#             lag.plot(network.lagraLoss, 'r-')\n",
    "\n",
    "            \n",
    "            zLLoss = fig.add_subplot(gs[3,:])\n",
    "            zLLoss.set_title('output layer zL')\n",
    "            zLLoss.plot(network.zConstrLoss[L], 'k-')\n",
    "            \n",
    "            total = fig.add_subplot(gs[4,:])\n",
    "            total.set_title('total loss ')\n",
    "            total.plot(network.totalLoss, 'r-')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 784)\n"
     ]
    }
   ],
   "source": [
    "Ypred = network.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0.880000\n",
    "# print network.dataLoss\n",
    "# print network.zConstrLoss[L-1]\n",
    "# print network.aConstrLoss[L-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy: 0.802000\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_te, Y_tr, Y_te = getMiniPatch(X_train, Y_train, X_test, Y_test, 6000, 1000, 1)\n",
    "Ypred = network.predict(X_te)\n",
    "print 'Prediction accuracy: %f' %np.mean(Ypred == Y_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
